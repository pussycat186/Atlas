name: CI Performance Gate

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  performance-test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
    
    - name: Setup pnpm
      uses: pnpm/action-setup@v2
      with:
        version: 9.0.0
    
    - name: Install dependencies
      run: pnpm install --frozen-lockfile
    
    - name: Build services
      run: pnpm build
      
    - name: Start observability stack
      run: |
        docker-compose -f docker-compose.observability.yml up -d
        sleep 30
    
    - name: Start services
      run: |
        # Start services in background
        cd services/gateway && pnpm start &
        echo $! > gateway.pid
        
        cd services/witness-node && pnpm start &
        echo $! > witness.pid
        
        # Wait for services to be ready
        sleep 15
        
        # Health check
        curl -f http://localhost:8080/health || exit 1
        curl -f http://localhost:8091/witness/health || exit 1
    
    - name: Install k6
      run: |
        sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
        echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
        sudo apt-get update
        sudo apt-get install k6
    
    - name: Run performance test
      run: |
        # Create k6 test script
        cat > k6-test.js << 'EOF'
        import http from 'k6/http';
        import { check, sleep } from 'k6';
        import { Rate } from 'k6/metrics';
        
        const errorRate = new Rate('errors');
        
        export const options = {
          scenarios: {
            constant_arrival_rate: {
              executor: 'constant-arrival-rate',
              rate: 500, // 500 RPS
              timeUnit: '1s',
              duration: '75s', // 15s warm-up + 60s measurement
              preAllocatedVUs: 100,
              maxVUs: 200,
            },
          },
          thresholds: {
            http_req_duration: ['p(95)<200'], // P95 < 200ms
            errors: ['rate<0.01'], // Error rate < 1%
            http_reqs: ['rate>=500'], // RPS >= 500
          },
        };
        
        export default function () {
          const payload = JSON.stringify({
            app: 'chat',
            record_id: `test_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
            payload: 'test message',
            meta: { test: true }
          });

          const params = {
              headers: {
                'Content-Type': 'application/json',
            },
          };

          const response = http.post('http://localhost:8080/record', payload, params);
          
          const result = check(response, {
            'status is 200': (r) => r.status === 200,
            'response time < 200ms': (r) => r.timings.duration < 200,
          });
          
          errorRate.add(!result);
          sleep(0.1);
        }
        EOF
        
        # Run k6 test
        k6 run --out json=k6-results.json k6-test.js
        
    - name: Parse performance results
      run: |
        # Extract metrics from k6 results
        python3 << 'EOF'
        import json
        import sys

        try:
            with open('k6-results.json', 'r') as f:
                data = [json.loads(line) for line in f if line.strip()]
            
            # Filter to measurement window (last 60 seconds)
            measurement_data = [d for d in data if d.get('type') == 'Point' and d.get('metric') == 'http_reqs']
            
            if not measurement_data:
                print("ERROR: No measurement data found")
                sys.exit(1)
            
            # Calculate metrics
            total_requests = len(measurement_data)
            duration = 60  # seconds
            rps = total_requests / duration
            
            # Get P95 latency
            durations = [d.get('data', {}).get('value', 0) for d in data if d.get('type') == 'Point' and d.get('metric') == 'http_req_duration']
            durations.sort()
            p95_index = int(len(durations) * 0.95)
            p95_latency = durations[p95_index] if durations else 0
            
            # Get error rate
            errors = [d for d in data if d.get('type') == 'Point' and d.get('metric') == 'errors']
            error_rate = sum(d.get('data', {}).get('value', 0) for d in errors) / total_requests if total_requests > 0 else 0
            
            # Create summary
            summary = {
                "rps": rps,
                "p95_latency_ms": p95_latency,
                "error_rate": error_rate,
                "total_requests": total_requests,
                "duration_seconds": duration
            }
            
            with open('k6-summary.json', 'w') as f:
                json.dump(summary, f, indent=2)
            
            print(f"Performance Results:")
            print(f"  RPS: {rps:.2f}")
            print(f"  P95 Latency: {p95_latency:.2f}ms")
            print(f"  Error Rate: {error_rate:.4f}")
            print(f"  Total Requests: {total_requests}")
            
            # Check thresholds
            if rps < 500:
                print("❌ FAIL: RPS below threshold (500)")
                sys.exit(1)
            if p95_latency > 200:
                print("❌ FAIL: P95 latency above threshold (200ms)")
                sys.exit(1)
            if error_rate > 0.01:
                print("❌ FAIL: Error rate above threshold (1%)")
                sys.exit(1)
            
            print("✅ PASS: All performance thresholds met")
            
        except Exception as e:
            print(f"ERROR: {e}")
            sys.exit(1)
        EOF
    
    - name: Upload performance results
      uses: actions/upload-artifact@v3
      with:
        name: performance-results
        path: |
          k6-results.json
          k6-summary.json
          
    - name: Performance Gate Check
      run: |
        if [ ! -f k6-summary.json ]; then
          echo "❌ Performance test failed - no summary file"
          exit 1
        fi
        
        # Check if all thresholds are met
        python3 << 'EOF'
        import json
        import sys

        with open('k6-summary.json', 'r') as f:
            summary = json.load(f)
        
        rps = summary['rps']
        p95_latency = summary['p95_latency_ms']
        error_rate = summary['error_rate']
        
        print(f"Performance Gate Results:")
        print(f"  RPS: {rps:.2f} (target: >=500)")
        print(f"  P95 Latency: {p95_latency:.2f}ms (target: <=200ms)")
        print(f"  Error Rate: {error_rate:.4f} (target: <=0.01)")
        
        if rps >= 500 and p95_latency <= 200 and error_rate <= 0.01:
            print("✅ PERFORMANCE GATE PASSED")
        else:
            print("❌ PERFORMANCE GATE FAILED")
            sys.exit(1)
        EOF
    
    - name: Cleanup
      if: always()
      run: |
        # Stop services
        if [ -f gateway.pid ]; then
          kill $(cat gateway.pid) || true
        fi
        if [ -f witness.pid ]; then
          kill $(cat witness.pid) || true
        fi
        
        # Stop observability stack
        docker-compose -f docker-compose.observability.yml down